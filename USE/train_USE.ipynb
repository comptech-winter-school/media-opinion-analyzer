{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "train_USE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7nElVyKGUxq"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import gensim\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aksOsrfQ2J82"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQvEKHPPlY4p",
        "outputId": "0ec5ed9b-ad52-4919-bbea-ff3d2a0c16a5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpaUEpuSDzsY"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idHz_xW7QXrg"
      },
      "source": [
        "### Upload data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd-1YYK-uXKX",
        "outputId": "88750b2f-7366-49b3-bc53-d193c32d56a7"
      },
      "source": [
        "os.listdir(\"/content/drive/MyDrive/comments\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['JoeBiden_comments_2020_all.csv',\n",
              " 'The_Donald_comments_2020_hourly.csv',\n",
              " 'Trump_comments_2020_all.csv',\n",
              " 'Trump_comments_2020_clean.csv',\n",
              " 'JoeBiden_comments_2020_clean.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmTLkFBfGUyD"
      },
      "source": [
        "#comments_dir = \"Lecture - Text embeddings (Medvedev)/codes/comments\"\n",
        "comments_dir = \"/content/drive/MyDrive/comments\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGyAeLESGUyE"
      },
      "source": [
        "# TRUMP COMMENTS\n",
        "trump_comments_file = \"./Trump_comments_2020_clean.csv\"\n",
        "trump_comments_path = os.path.join(comments_dir, trump_comments_file)\n",
        "trump_df = pd.read_csv(trump_comments_path, index_col = 0)\n",
        "\n",
        "\n",
        "# BIDEN COMMENTS\n",
        "biden_comments_file = './JoeBiden_comments_2020_clean.csv'\n",
        "biden_comments_path = os.path.join(comments_dir, biden_comments_file)\n",
        "biden_df = pd.read_csv(biden_comments_path, index_col = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffxTyeVRN2CS"
      },
      "source": [
        "trump_df['who'] = 0\n",
        "biden_df['who'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxerYtvUM3Eh"
      },
      "source": [
        "all_df = pd.concat([trump_df, biden_df])\n",
        "all_df = all_df.reset_index(drop=True)\n",
        "all_df = all_df.drop(['author', 'created_utc', 'link_id', 'parent_id', 'score'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCECF-XSmkfq",
        "outputId": "4db37bfb-21c5-4134-a65c-c8bd8c42ccb1"
      },
      "source": [
        "len(trump_df), len(biden_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(618858, 499528)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qD7simhQ4PL"
      },
      "source": [
        "biden_df = biden_df[:20000]\n",
        "trump_df = trump_df[:20000]\n",
        "trump_df['who'] = 0 # 0 == trump\n",
        "biden_df['who'] = 1 # 1 == biden\n",
        "all_df = pd.concat([trump_df, biden_df])\n",
        "all_df = all_df.reset_index(drop=True)\n",
        "all_df[\"body\"] = all_df[\"body\"].apply(str)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFN86krMQDFN"
      },
      "source": [
        "del(trump_df)\n",
        "del(biden_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY8hF8SHVI5H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr9YgI1uD86Z"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNFDL3OyXYiq",
        "outputId": "b6737c61-0b6c-45b0-a512-b24929107bb4"
      },
      "source": [
        "!pip install tensorflow==1.15\r\n",
        "!pip install \"tensorflow_hub>=0.6.0\"\r\n",
        "!pip3 install tensorflow_text==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (53.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow_hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub>=0.6.0) (53.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub>=0.6.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow_text==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: tensorflow<1.16,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.32.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.36.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (53.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZzsaBqCWCSF"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzL4jJooVtic"
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95fkVeVhVbuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f596a98-5aca-4b0b-e7e2-1779e91185db"
      },
      "source": [
        "# Import the Universal Sentence Encoder's TF Hub module\r\n",
        "embed = hub.Module(module_url)\r\n",
        "\r\n",
        "# Compute a representation for each message, showing various lengths supported.\r\n",
        "word = \"Elephant\"\r\n",
        "sentence = \"I am a sentence for which I would like to get its embedding.\"\r\n",
        "paragraph = (\r\n",
        "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\r\n",
        "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\r\n",
        "    \"the more 'diluted' the embedding will be.\")\r\n",
        "messages = [word, sentence, paragraph]\r\n",
        "\r\n",
        "with tf.Session() as session:\r\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\r\n",
        "  message_embeddings = session.run(embed(messages))\r\n",
        "\r\n",
        "  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\r\n",
        "    print(\"Message: {}\".format(messages[i]))\r\n",
        "    print(\"Embedding size: {}\".format(len(message_embedding)))\r\n",
        "    message_embedding_snippet = \", \".join(\r\n",
        "        (str(x) for x in message_embedding[:3]))\r\n",
        "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Message: Elephant\n",
            "Embedding size: 512\n",
            "Embedding: [-0.016987258568406105, -0.008949847891926765, -0.007062715478241444, ...]\n",
            "\n",
            "Message: I am a sentence for which I would like to get its embedding.\n",
            "Embedding size: 512\n",
            "Embedding: [0.03531331941485405, -0.025384265929460526, -0.007880021817982197, ...]\n",
            "\n",
            "Message: Universal Sentence Encoder embeddings also support short paragraphs. There is no hard limit on how long the paragraph is. Roughly, the longer the more 'diluted' the embedding will be.\n",
            "Embedding size: 512\n",
            "Embedding: [0.018790993839502335, 0.04536517709493637, -0.02001088112592697, ...]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox-6qSneVbJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a585eecc-a457-4f35-e511-2181fac130ab"
      },
      "source": [
        "vecs = list()\r\n",
        "with tf.Session() as session:\r\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\r\n",
        "  step = 5000\r\n",
        "  for i in range(step, len(all_df)+step, step):\r\n",
        "    print(i)\r\n",
        "    tmp_vecs = session.run(embed(list(all_df[\"body\"][i-step:i])))\r\n",
        "    vecs.append(tmp_vecs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "15000\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "20000\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "30000\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "35000\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "40000\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qg1zKBFK8xe"
      },
      "source": [
        "vecs = [item for sublist in vecs for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVCcetp8NTLi",
        "outputId": "9f666cf6-2491-4de0-9d78-1ec256dcefa3"
      },
      "source": [
        "len(vecs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ius4-MGed1WL"
      },
      "source": [
        "assert(len(vecs) == len(all_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B0IRPbGNz3N"
      },
      "source": [
        "all_df[\"vec\"] = vecs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5t9HiJNVcRk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "bb5e7f23-e2f4-4587-e3e9-7f7b4137f6b7"
      },
      "source": [
        "all_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>link_id</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>score</th>\n",
              "      <th>who</th>\n",
              "      <th>vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>khalabrakis</td>\n",
              "      <td>Fighters... That means warrior, like people wh...</td>\n",
              "      <td>1577836803</td>\n",
              "      <td>t3_ei6h2x</td>\n",
              "      <td>t3_ei6h2x</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.045877255, -0.0048621236, -0.023708122, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Whopper_Jr</td>\n",
              "      <td>it is plausible that Republicans will never wi...</td>\n",
              "      <td>1577836806</td>\n",
              "      <td>t3_ei4ag7</td>\n",
              "      <td>t3_ei4ag7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.0047475738, 0.031999968, -0.029850133, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sustainable_Saltmine</td>\n",
              "      <td>we must send bartenders back to bartending and...</td>\n",
              "      <td>1577836807</td>\n",
              "      <td>t3_eiay7b</td>\n",
              "      <td>t3_eiay7b</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.009444212, 0.005957485, -0.00456313, 0.003...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TheC0zmo</td>\n",
              "      <td>Bullshit. you are blaming a fiscally conservat...</td>\n",
              "      <td>1577836814</td>\n",
              "      <td>t3_ei40gl</td>\n",
              "      <td>t1_fco5fri</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.048155, 0.035600815, -0.031101977, 0.062596...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>brotherjustincrowe</td>\n",
              "      <td>Military R&amp;amp;D and intel is not \"no reason.\"...</td>\n",
              "      <td>1577836818</td>\n",
              "      <td>t3_ei51lq</td>\n",
              "      <td>t1_fcodqek</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.018903375, -0.044530015, -0.021175865, -0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 author  ...                                                vec\n",
              "0           khalabrakis  ...  [0.045877255, -0.0048621236, -0.023708122, 0.0...\n",
              "1            Whopper_Jr  ...  [0.0047475738, 0.031999968, -0.029850133, -0.0...\n",
              "2  Sustainable_Saltmine  ...  [-0.009444212, 0.005957485, -0.00456313, 0.003...\n",
              "3              TheC0zmo  ...  [0.048155, 0.035600815, -0.031101977, 0.062596...\n",
              "4    brotherjustincrowe  ...  [-0.018903375, -0.044530015, -0.021175865, -0....\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0yVWDw220JY"
      },
      "source": [
        "all_df = all_df.drop(columns=[\"author\", \"created_utc\", \"link_id\", \t\"parent_id\", \t\"score\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJjsiFlp2ikq"
      },
      "source": [
        "pickle.dump(all_df, open(\"df_use.pickle\", 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-5H2_saVcVp"
      },
      "source": [
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3gRaP70VhmN"
      },
      "source": [
        "def cosine_similarity(a,b):\r\n",
        "  return (1 - cosine(a,b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSE43iPNVhoo"
      },
      "source": [
        "# trump_sim2 = []\r\n",
        "# biden_sim2 = []\r\n",
        "# tb_sim2 = []\r\n",
        "\r\n",
        "# sample_value = 1000\r\n",
        "\r\n",
        "# for i in range(sample_value):\r\n",
        "#   trump_sample_1 = all_df.loc[all_df['who'] == 1][\"vec\"].sample().values[0]\r\n",
        "#   trump_sample_2 = all_df.loc[all_df['who'] == 1][\"vec\"].sample().values[0]\r\n",
        "#   trump_sim2.append(cosine_similarity(trump_sample_1, trump_sample_2))\r\n",
        "\r\n",
        "#   biden_sample_1 = all_df.loc[all_df['who'] == 0][\"vec\"].sample().values[0]\r\n",
        "#   biden_sample_2 = all_df.loc[all_df['who'] == 0][\"vec\"].sample().values[0]\r\n",
        "#   biden_sim2.append(cosine_similarity(biden_sample_1, biden_sample_2))\r\n",
        "\r\n",
        "#   tb_sim2.append(cosine_similarity(biden_sample_1, trump_sample_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-Loi-dxVhrW"
      },
      "source": [
        "# plt.hist(trump_sim2, label='trump')\r\n",
        "# plt.hist(biden_sim2, label='biden')\r\n",
        "# plt.hist(tb_sim2, label='trump & biden')\r\n",
        "# plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USkcJGGeVmnb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgoERWd2Vm2C"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq_h0lxG2M3c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxIzdwIRVhtu"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn import utils\r\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k0z6XMiVhwI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9078633c-e2f9-41bd-925d-6f6374575ea6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(all_df[\"vec\"].tolist(), all_df[\"who\"].tolist())\r\n",
        "\r\n",
        "\r\n",
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\r\n",
        "logreg.fit(X_train, y_train)\r\n",
        "y_pred = logreg.predict(X_test)\r\n",
        "print(classification_report(y_test, y_pred))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.86      0.85      5049\n",
            "           1       0.85      0.84      0.84      4951\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c985ECCg2G7O",
        "outputId": "7eda3291-e23a-422c-d5d1-22e6526fc8fd"
      },
      "source": [
        "filename = 'USE_model.pickle'\r\n",
        "pickle.dump(logreg, open(filename, 'wb'))\r\n",
        " \r\n",
        "# some time later...\r\n",
        " \r\n",
        "# load the model from disk\r\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\r\n",
        "result = loaded_model.score(X_test, y_test)\r\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XMLLx4IRWn4"
      },
      "source": [
        "#!pip install umap-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYnQPv_DgX1r"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = [12, 8]\r\n",
        "plt.rcParams['figure.dpi'] = 200 # 200 e.g. is really fine, but slower"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwkTRZ0TRW8H"
      },
      "source": [
        "import umap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5w9vzBTRXWL"
      },
      "source": [
        "reducer = umap.UMAP(n_neighbors=3, min_dist=0.001, metric='cosine')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWQfiXZ_RZGv"
      },
      "source": [
        "embedding = reducer.fit_transform(all_df[\"vec\"].tolist())\r\n",
        "embedding.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir7aoIgTshRx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prp48dQZRZJT"
      },
      "source": [
        "plt.scatter(\r\n",
        "    embedding[:, 0],\r\n",
        "    embedding[:, 1],\r\n",
        "    c=all_df[\"who\"].tolist(), cmap='Spectral', s=10, alpha=0.1, edgecolors = 'face')\r\n",
        "plt.gca().set_aspect('equal', 'datalim')\r\n",
        "plt.title('UMAP projection of the dataset', fontsize=24)\r\n",
        "plt.figure(figsize=(10,7))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYQzSLSpdUFz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}